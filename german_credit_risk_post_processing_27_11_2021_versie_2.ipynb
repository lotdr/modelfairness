{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction: Post-processing with Reject Option Classification](#introduction)\n",
    "1. [Load all necessary packages](#paragraph2)\n",
    "1. [Create the dataframe from a csv file](#paragraph3)\n",
    "1. [Create an aif360 dataset from the dataframe](#paragraph4)\n",
    "    1. [Convert the dataframe into an aif360 dataset](#subparagraph4.1)\n",
    "    1. [Split into training, validation, and testing datasets](#subparagraph4.2)\n",
    "    1. [Display properties of the datasets](#subparagraph4.3)\n",
    "    1. [Compute raw fairness for datasetss - age category as protected attribute, privileged group 1 (25+ year old) and unprivileged group 0 (younger than 25)](#subparagraph4.4)\n",
    "    1. [Scale training data and use that scaler to transform the validation and testing datasets](#subparagraph4.5)\n",
    "1. [Logistic Regression (LR)](#paragraph5)\n",
    "    1. [Build a LR model on training data](#subparagraph5.1)\n",
    "    1. [Fairness metrics for LR model, before correcting for bias](#subparagraph5.2)\n",
    "    1. [Post-processing the LR  model with ROC, optimizing Disparate Impact](#subparagraph5.3)\n",
    "    1. [Fairness metrics for LR model, after correcting for bias (with optimized Disparate Impact)](#subparagraph5.4)\n",
    "    1. [Post-processing the LR  model with ROC, optimizing Difference in Odds](#subparagraph5.5)\n",
    "    1. [Fairness metrics for LR model, after correcting for bias (with optimized Difference in Odds)](#subparagraph5.6)\n",
    "    1. [Post-processing the LR model with EqOddsPostprocessing](#subparagraph5.7)\n",
    "    1. [Fairness metrics for LR model, after correcting for bias (with optimized Equalized Odds)](#subparagraph5.8)\n",
    "1. [Extreme Gradient Boosting (XGB)](#paragraph6)\n",
    "    1. [Build an XGB model on training data](#subparagraph6.1)\n",
    "    1. [Fairness metrics for XGB model, before correcting for bias](#subparagraph6.2)\n",
    "    1. [Post-processing the XGB  model with ROC, optimizing Disparate Impact](#subparagraph6.3)\n",
    "    1. [Fairness metrics for XGB model, after correcting for bias (with optimized Disparate Impact)](#subparagraph6.4)\n",
    "    1. [Post-processing the XGB  model with ROC, optimizing Difference in Odds](#subparagraph6.5)\n",
    "    1. [Fairness metrics for XGB model, after correcting for bias (with optimized Difference in Odds)](#subparagraph6.6))\n",
    "    1. [Post-processing the XGB model with EqOddsPostprocessing](#subparagraph6.7)\n",
    "    1. [Fairness metrics for XGB model, after correcting for bias (with optimized Equalized Odds)](#subparagraph6.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "* https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "* https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5c0873e6-219a-46f2-89e9-0468d3e0b71a"
   },
   "source": [
    "# 1. Introduction: Post-processing with Reject Option Classification <a name='introduction'></a>\n",
    "\n",
    "#### This notebook uses the Reject Option Classification (ROC) post-processing algorithm for bias mitigation. The steps are:\n",
    "* All necessary packages are imported\n",
    "* The csv file is imported to create a pandas dataframe\n",
    "* An aif360 dataset is created from the pandas dataframe. This step is critical for the analysis because the ROC algorithm does not operate on a pandas dataframe but on an aif360 dataset. The aif360 dataset is also split into a training set, validation set, and testing set (70%, 15%, and 15% of the dataset, respectively)\n",
    "* A Logistic Regression model is built, optimizing the Balanced Accuracy metric. The predictions from this model are processed by ROC so that (more) fair predictions are obtained (\"fair\" as determined by the Disparate Impact metric)\n",
    "* An Extreme Gradient Boosting is built, with tuning the parameters by cross validation and optimizing the Balanced Accuracy metric. The predictions from this model are processed by ROC so that (more) fair predictions are obtained (\"fair, again according the Disparate Impact metric).\n",
    "\n",
    "#### References:\n",
    "* <a href=\"https://towardsdatascience.com/reducing-ai-bias-with-rejection-option-based-classification-54fefdb53c2\">Introduction to fairness with post-processing</a>\n",
    "* <a href=\"https://aif360.mybluemix.net\">IBM aif3360 library/a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load all necessary packages <a name=\"paragraph2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e259f25b1c104b3b8fe188cad81b7e42"
   },
   "source": [
    "!pip install \n",
    "\n",
    "missingno_found = !pip list | grep missingno != \"\"\n",
    "if not missingno_found:\n",
    "    !pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "96d5de63b0c0408184a9cc00a388007e"
   },
   "outputs": [],
   "source": [
    "# install and import IBM's fairness package\n",
    "aif360_found = !pip list | grep aif360 != \"\"\n",
    "if not aif360_found:\n",
    "    !pip install aif360\n",
    "    \n",
    "import aif360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "81ab51a1b330404eb9700c90a4e72045"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from ipywidgets import interactive, FloatSlider\n",
    "\n",
    "\n",
    "#import sys\n",
    "#sys.path.append(\"../\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "#import missingno as msno\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "81ab51a1b330404eb9700c90a4e72045"
   },
   "outputs": [],
   "source": [
    "# import aif360 datasets and BinaryLabelDataset\n",
    "import aif360.datasets\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "#from aif360.datasets import AdultDataset, GermanDataset, CompasDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "81ab51a1b330404eb9700c90a4e72045"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n"
     ]
    }
   ],
   "source": [
    "# import fairness metrics\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        import aif360.metrics\n",
    "    except:\n",
    "         continue\n",
    "    else:\n",
    "         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "81ab51a1b330404eb9700c90a4e72045"
   },
   "outputs": [],
   "source": [
    "from aif360.algorithms.postprocessing.reject_option_classification\\\n",
    "        import RejectOptionClassification\n",
    "\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        from aif360.metrics import BinaryLabelDatasetMetric\n",
    "    except:\n",
    "         continue\n",
    "    else:\n",
    "         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Equalized Post Processing module\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "    except:\n",
    "         continue\n",
    "    else:\n",
    "         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "81ab51a1b330404eb9700c90a4e72045"
   },
   "outputs": [],
   "source": [
    "# import StandardScaler to transform to mean 0, standard deviation 1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import machine learning algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2b82b7032ae2462e8c2ad6dfb366c3f6"
   },
   "outputs": [],
   "source": [
    "def compute_classification_metrics (dataset_orig_trn, dataset_pred_trn,\n",
    "                                    dataset_orig_vld, dataset_pred_vld,\n",
    "                                    dataset_orig_tst, dataset_pred_tst):\n",
    "    \"\"\"\n",
    "    Computes classification metrics for training, validation and testing data, \n",
    "    using the aif360 ClassificationMetric function\n",
    "    \n",
    "    Input: \n",
    "    - dataset_orig: original dataset with labels\n",
    "    - dataset_pred: dataset with predictions (possibly the transformed predictions, transformed by postprocessing)\n",
    "    \n",
    "    Returns:\n",
    "    - accuracy\n",
    "    - balanced accuracy\n",
    "    - absolute difference in odds\n",
    "    - disparate impact\n",
    "    \"\"\"\n",
    "    \n",
    "    metrics =  [-1] * 15\n",
    "    \n",
    "    cm_train = ClassificationMetric(dataset_orig_trn,\n",
    "                                    dataset_pred_trn,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    \n",
    "    metrics [0]  = cm_train.accuracy()\n",
    "    metrics [1]  = (cm_train.true_positive_rate() + cm_train.true_negative_rate())/ 2\n",
    "    metrics [2]  = cm_train.average_abs_odds_difference()\n",
    "    metrics [3]  = cm_train.average_odds_difference()\n",
    "    metrics [4]  = cm_train.disparate_impact()\n",
    "    \n",
    "    \n",
    "    cm_valid = ClassificationMetric(dataset_orig_vld,\n",
    "                              dataset_pred_vld,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    \n",
    "    metrics [5] = cm_valid.accuracy()\n",
    "    metrics [6] = (cm_valid.true_positive_rate() + cm_valid.true_negative_rate())/ 2\n",
    "    metrics [7] = cm_valid.average_abs_odds_difference()\n",
    "    metrics [8] = cm_valid.average_odds_difference()\n",
    "    metrics [9] = cm_valid.disparate_impact()\n",
    "    \n",
    "    \n",
    "    cm_test = ClassificationMetric(dataset_orig_tst,\n",
    "                              dataset_pred_tst,\n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "    \n",
    "    metrics [10] = cm_test.accuracy()\n",
    "    metrics [11] = (cm_test.true_positive_rate() + cm_test.true_negative_rate())/ 2\n",
    "    metrics [12] = cm_test.average_abs_odds_difference()\n",
    "    metrics [13] = cm_test.average_odds_difference()\n",
    "    metrics [14] = cm_test.disparate_impact()\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_metrics(metrics):\n",
    "    \"\"\"\n",
    "    Prints the classification metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range (len(metrics)):\n",
    "        if i <= 4:\n",
    "            if i == 0:\n",
    "                display(Markdown(\"##### Results for the training dataset\\n\"))\n",
    "                print (\"Accuracy:\\t\\t\\t\", round (metrics[0], 3))\n",
    "            if i == 1:\n",
    "                print (\"Balanced Accuracy:\\t\\t\", round (metrics[1], 3))\n",
    "            if i == 2:\n",
    "                print(\"Absolute difference in odds:\\t\", round(metrics[2], 3))\n",
    "            if i == 3:\n",
    "                print(\"Difference in odds:\\t\\t\", round(metrics[3], 3)) \n",
    "            if i == 4:\n",
    "                print(\"Disparate impact:\\t\\t\", round(metrics[4], 3))\n",
    "        elif i <= 9:\n",
    "            if i == 5:\n",
    "                display(Markdown(\"##### Results for the validation dataset\\n\"))\n",
    "                print (\"Accuracy:\\t\\t\\t\", round (metrics[5], 3))\n",
    "            if i == 6:\n",
    "                print (\"Balanced Accuracy:\\t\\t\", round (metrics[6], 3))\n",
    "            if i == 7:\n",
    "                print(\"Absolute difference in odds:\\t\", round(metrics[7], 3))\n",
    "            if i == 8:\n",
    "                print(\"Difference in odds:\\t\\t\", round(metrics[8], 3))\n",
    "            if i == 9:\n",
    "                print(\"Disparate impact:\\t\\t\", round(metrics[9], 3))\n",
    "        else:\n",
    "            if i == 10:\n",
    "                display(Markdown(\"##### Results for the testing dataset\\n\"))\n",
    "                print (\"Accuracy:\\t\\t\\t\", round (metrics[10], 3))\n",
    "            if i == 11:\n",
    "                print (\"Balanced Accuracy:\\t\\t\", round (metrics[11], 3))\n",
    "            if i == 12:\n",
    "                print(\"Absolute difference in odds:\\t\", round(metrics[12], 3))\n",
    "            if i == 13:\n",
    "                print(\"Difference in odds:\\t\\t\", round(metrics[13], 3))\n",
    "            if i == 14:\n",
    "                print(\"Disparate impact:\\t\\t\", round(metrics[14], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the dataframe from a csv file<a name=\"paragraph3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ea94700ffe854207b2ec68852d1de872"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration in month</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Installment rate in percentage of disposable income</th>\n",
       "      <th>Present residence since</th>\n",
       "      <th>Number of existing credits at this bank</th>\n",
       "      <th>Number of people being liable to provide maintenance for</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>marital_status_divorced/separated</th>\n",
       "      <th>marital_status_divorced/separated/married</th>\n",
       "      <th>marital_status_married/widowed</th>\n",
       "      <th>...</th>\n",
       "      <th>Housing_rent</th>\n",
       "      <th>Job_management/ highly qualified employee</th>\n",
       "      <th>Job_skilled employee / official</th>\n",
       "      <th>Job_unemployed/ unskilled  - non-resident</th>\n",
       "      <th>Job_unskilled - resident</th>\n",
       "      <th>Telephone_none</th>\n",
       "      <th>Telephone_yes</th>\n",
       "      <th>foreign worker_no</th>\n",
       "      <th>foreign worker_yes</th>\n",
       "      <th>good_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>5951</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>2096</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>7882</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>4870</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Duration in month  Credit amount  \\\n",
       "0                  6           1169   \n",
       "1                 48           5951   \n",
       "2                 12           2096   \n",
       "3                 42           7882   \n",
       "4                 24           4870   \n",
       "\n",
       "   Installment rate in percentage of disposable income  \\\n",
       "0                                                  4     \n",
       "1                                                  2     \n",
       "2                                                  2     \n",
       "3                                                  2     \n",
       "4                                                  3     \n",
       "\n",
       "   Present residence since  Number of existing credits at this bank  \\\n",
       "0                        4                                        2   \n",
       "1                        2                                        1   \n",
       "2                        3                                        1   \n",
       "3                        4                                        1   \n",
       "4                        4                                        2   \n",
       "\n",
       "   Number of people being liable to provide maintenance for  gender_male  \\\n",
       "0                                                  1                   1   \n",
       "1                                                  1                   0   \n",
       "2                                                  2                   1   \n",
       "3                                                  2                   1   \n",
       "4                                                  2                   1   \n",
       "\n",
       "   marital_status_divorced/separated  \\\n",
       "0                                  0   \n",
       "1                                  0   \n",
       "2                                  0   \n",
       "3                                  0   \n",
       "4                                  0   \n",
       "\n",
       "   marital_status_divorced/separated/married  marital_status_married/widowed  \\\n",
       "0                                          0                               0   \n",
       "1                                          1                               0   \n",
       "2                                          0                               0   \n",
       "3                                          0                               0   \n",
       "4                                          0                               0   \n",
       "\n",
       "   ...  Housing_rent  Job_management/ highly qualified employee  \\\n",
       "0  ...             0                                          0   \n",
       "1  ...             0                                          0   \n",
       "2  ...             0                                          0   \n",
       "3  ...             0                                          0   \n",
       "4  ...             0                                          0   \n",
       "\n",
       "   Job_skilled employee / official  Job_unemployed/ unskilled  - non-resident  \\\n",
       "0                                1                                          0   \n",
       "1                                1                                          0   \n",
       "2                                0                                          0   \n",
       "3                                1                                          0   \n",
       "4                                1                                          0   \n",
       "\n",
       "   Job_unskilled - resident  Telephone_none  Telephone_yes  foreign worker_no  \\\n",
       "0                         0               0              1                  0   \n",
       "1                         0               1              0                  0   \n",
       "2                         1               1              0                  0   \n",
       "3                         0               1              0                  0   \n",
       "4                         0               1              0                  0   \n",
       "\n",
       "   foreign worker_yes  good_risk  \n",
       "0                   1          1  \n",
       "1                   1          0  \n",
       "2                   1          1  \n",
       "3                   1          1  \n",
       "4                   1          0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_path = \"C:/Users/Gebruiker/Lotte_Thesis/\"\n",
    "my_filename = \"german_credit_data_prepared.csv\"\n",
    "my_path_filename = my_path + my_filename\n",
    "df_new = pd.read_csv(my_path_filename)\n",
    "#cols_to_drop = [\"gender_male\", \"marital_status_divorced/separated\", \"marital_status_divorced/separated/married\",\n",
    "#                \"marital_status_married/widowed\", \"marital_status_single\"]\n",
    "#df_new.drop(cols_to_drop, axis=1, inplace=True)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "db08a1e0-fa4e-4e2f-8da6-cc45863f1082"
   },
   "source": [
    "## 4. Create an aif360 dataset from the dataframe <a name=\"paragraph4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Convert the dataframe into an aif360 dataset <a name=\"subparagraph4.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "a2d546e3-d720-46a6-b90d-a44e8e3a1be1"
   },
   "outputs": [],
   "source": [
    "# aif360 algorithms work on a \"aif360\" dataset, so convert the dataframe into an aif360 dataset\n",
    "\n",
    "dataset_orig = aif360.datasets.BinaryLabelDataset(df=df_new,\n",
    "                                                  label_names=['good_risk'],\n",
    "                                                  protected_attribute_names=['age_25plus'],\n",
    "                                                  favorable_label = 1.0,\n",
    "                                                  unfavorable_label=0.0,\n",
    "                                                  privileged_protected_attributes =  [[1]],\n",
    "                                                  unprivileged_protected_attributes =  [[0]]\n",
    "                                                 )       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "443bda06-f595-4129-a0b8-20eda06d703a"
   },
   "source": [
    "### B. Split into training, validation, and testing datasets<a name=\"subparagraph4.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eb462495-78c9-4cec-b77b-942b7fd661c7"
   },
   "outputs": [],
   "source": [
    "# Get the dataset and split into train and test\n",
    "dataset_orig_train, dataset_orig_vt = dataset_orig.split([0.7], shuffle=True)\n",
    "dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68ac2666-ac68-45ae-a1d3-581397817ac5"
   },
   "source": [
    "### C. Display properties of the datasets  <a name=\"subparagraph4.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "14fc8be7-f2ab-48df-acca-2fd92eabaf15"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 62)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Validation Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 62)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Testing Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 62)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age_25plus']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]] [[0]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Duration in month', 'Credit amount', 'Installment rate in percentage of disposable income', 'Present residence since', 'Number of existing credits at this bank', 'Number of people being liable to provide maintenance for', 'gender_male', 'marital_status_divorced/separated', 'marital_status_divorced/separated/married', 'marital_status_married/widowed', 'marital_status_single', 'age_25plus', 'Status of existing checking account_0 <= <200 DM', 'Status of existing checking account_<0 DM', 'Status of existing checking account_>= 200 DM ', 'Status of existing checking account_no checking account', 'Credit history_all credits at this bank paid back duly', 'Credit history_critical account', 'Credit history_delay in paying off', 'Credit history_existing credits paid back duly till now', 'Credit history_no credits taken', 'Purpose_business', 'Purpose_car (new)', 'Purpose_car (used)', 'Purpose_domestic appliances', 'Purpose_education', 'Purpose_furniture/equipment', 'Purpose_others', 'Purpose_radio/television', 'Purpose_repairs', 'Purpose_retraining', 'Savings account/bonds_100 <= <500 DM', 'Savings account/bonds_500 <= < 1000 DM', 'Savings account/bonds_<100 DM', 'Savings account/bonds_>= 1000 DM', 'Savings account/bonds_no savings account', 'Present employment since_1<= < 4 years', 'Present employment since_4<= <7 years', 'Present employment since_<1 years', 'Present employment since_>=7 years', 'Present employment since_unemployed', 'Other debtors / guarantors_co-applicant', 'Other debtors / guarantors_guarantor', 'Other debtors / guarantors_none', 'Property_car or other', 'Property_real estate', 'Property_savings agreement/life insurance', 'Property_unknown / no property', 'Other installment plans_bank', 'Other installment plans_none', 'Other installment plans_store', 'Housing_for free', 'Housing_own', 'Housing_rent', 'Job_management/ highly qualified employee', 'Job_skilled employee / official', 'Job_unemployed/ unskilled  - non-resident', 'Job_unskilled - resident', 'Telephone_none', 'Telephone_yes', 'foreign worker_no', 'foreign worker_yes']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Validation Dataset shape\"))\n",
    "print(dataset_orig_valid.features.shape)\n",
    "display(Markdown(\"#### Testing Dataset shape\"))\n",
    "print(dataset_orig_test.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "622bafcc-4712-413d-a9ac-a51abca2a591"
   },
   "source": [
    "### D. Compute raw fairness for datasetss - age category as protected attribute, privileged group 1 (25+ year old) and unprivileged group 0 (younger than 25)<a name=\"subparagraph4.4\"></a>\n",
    "\n",
    "* \"raw\" fairness: fairness without a model; here, just look at the difference between the proportion good risk of the unprivileged group and the proportion good risk of the privileged group.\n",
    "* The difference is computed as: proportion good risk unprivileged group - proportion good risk privileged group, so negative values indicate bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7576a2540b2646538d8e965912deeecb"
   },
   "outputs": [],
   "source": [
    "# Define privileged and unprivileged groups\n",
    "privileged_groups =   [{'age_25plus': 1}]\n",
    "unprivileged_groups = [{'age_25plus': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "69a0196e-4ae0-4643-863d-9903c2de5f6c"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Difference in mean outcomes between unprivileged and privileged group"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:\t -0.153\n",
      "Validation dataset:\t 0.034\n",
      "Testing dataset:\t -0.348\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Difference in mean outcomes between unprivileged and privileged group\"))\n",
    "print(\"Training dataset:\\t %.3f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "metric_orig_valid = BinaryLabelDatasetMetric(dataset_orig_valid, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Validation dataset:\\t %.3f\" % metric_orig_valid.mean_difference())\n",
    "\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test,\n",
    "                                            unprivileged_groups=unprivileged_groups,\n",
    "                                            privileged_groups=privileged_groups)\n",
    "print(\"Testing dataset:\\t %.3f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For training, validation, and testing set, those who are 25+ have a higher probability to be a good risk. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Scale training data and use that scaler to transform the validation and testing datasets<a name=\"subparagraph4.5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset by standardizing columns\n",
    "scale_orig = StandardScaler()\n",
    "\n",
    "# Fit and scale features in the training set\n",
    "X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "\n",
    "# Scale validation data\n",
    "X_valid = scale_orig.transform(dataset_orig_valid.features)\n",
    "#y_valid = dataset_orig_valid_pred.labels\n",
    "\n",
    "# Scale test data\n",
    "X_test = scale_orig.transform(dataset_orig_test.features)\n",
    "#y_test = dataset_orig_test_pred.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fa2b6de-25e0-4afd-adad-1065fb046b17"
   },
   "source": [
    "## 5. Logistic Regression (LR) <a name=\"paragraph5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for the predictions on the original datasets\n",
    "dataset_orig_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
    "dataset_orig_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "dataset_orig_test_pred  = dataset_orig_test.copy(deepcopy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14d2dcf3-47be-4265-8ca1-c158aa54994b"
   },
   "source": [
    "### A. Build a LR model on training data<a name=\"subparagraph5.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "8485aa83-f76a-439a-8d3d-12d9460322d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Logistic Regression and save the predictions to the training, validation and testing datasets\n",
    "lrmod = LogisticRegression()\n",
    "lrmod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient for age_25plus :\t 0.209\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficient of age_25plus, to see if there is bias\n",
    "lr_coeff = lrmod.coef_ [0]\n",
    "\n",
    "i = 0        \n",
    "for col in df_new.columns:\n",
    "    if col  == \"age_25plus\":\n",
    "        print (\"Coefficient for\", col, \":\\t %.3f\" %  lr_coeff[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The coefficient is positive, so 25+ year old people have a higher probability to be classified as good risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Fairness metrics for LR model, before correcting for bias<a name=\"subparagraph5.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The aif360 ClassificationMetric function only works for aif360 datasets, so add the predictions (probabilities and\n",
    "# and predicted labels) to the training, validation, and testing dtaasets (which are BinaryLabelDatasets)\n",
    "\n",
    "fav_idx = np.where(lrmod.classes_ == dataset_orig_train.favorable_label)[0][0]\n",
    "#pos_ind = np.where(lrmod.classes_ == dataset_orig_train.favorable_label)[0][0]\n",
    "\n",
    "# Prediction probs for training, validation and testing data\n",
    "y_train_pred_prob = lrmod.predict_proba(X_train)[:,fav_idx]\n",
    "y_valid_pred_prob = lrmod.predict_proba(X_valid)[:,fav_idx]\n",
    "y_test_pred_prob  = lrmod.predict_proba(X_test)[:,fav_idx]\n",
    "\n",
    "class_thresh = 0.5\n",
    "\n",
    "dataset_orig_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
    "dataset_orig_valid_pred.scores = y_valid_pred_prob.reshape(-1,1)\n",
    "dataset_orig_test_pred.scores  = y_test_pred_prob.reshape(-1,1)\n",
    "\n",
    "y_train_pred = np.zeros_like(dataset_orig_train_pred.labels)\n",
    "y_train_pred[y_train_pred_prob >= class_thresh] = dataset_orig_train_pred.favorable_label\n",
    "y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_orig_train_pred.unfavorable_label\n",
    "dataset_orig_train_pred.labels = y_train_pred\n",
    "\n",
    "y_valid_pred = np.zeros_like(dataset_orig_valid_pred.labels)\n",
    "y_valid_pred[y_valid_pred_prob >= class_thresh] = dataset_orig_valid_pred.favorable_label\n",
    "y_valid_pred[~(y_valid_pred_prob >= class_thresh)] = dataset_orig_valid_pred.unfavorable_label\n",
    "dataset_orig_valid_pred.labels = y_valid_pred\n",
    "\n",
    "y_test_pred = np.zeros_like(dataset_orig_test_pred.labels)\n",
    "y_test_pred[y_test_pred_prob >= class_thresh] = dataset_orig_test_pred.favorable_label\n",
    "y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_orig_test_pred.unfavorable_label\n",
    "dataset_orig_test_pred.labels = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Results for Logistic Regression before correcting for bias by post-processing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the training dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.779\n",
      "Balanced Accuracy:\t\t 0.699\n",
      "Absolute difference in odds:\t 0.101\n",
      "Difference in odds:\t\t -0.101\n",
      "Disparate impact:\t\t 0.786\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the validation dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.762\n",
      "Balanced Accuracy:\t\t 0.683\n",
      "Absolute difference in odds:\t 0.207\n",
      "Difference in odds:\t\t -0.207\n",
      "Disparate impact:\t\t 0.734\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the testing dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.789\n",
      "Balanced Accuracy:\t\t 0.718\n",
      "Absolute difference in odds:\t 0.256\n",
      "Difference in odds:\t\t -0.256\n",
      "Disparate impact:\t\t 0.525\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Results for Logistic Regression before correcting for bias by post-processing\"))\n",
    "\n",
    "lr_bef_class_metrics= compute_classification_metrics (dataset_orig_train, dataset_orig_train_pred,\n",
    "                                                      dataset_orig_valid, dataset_orig_valid_pred,\n",
    "                                                      dataset_orig_test,  dataset_orig_test_pred)\n",
    "\n",
    "print_classification_metrics(lr_bef_class_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b91a2401-653c-42bb-977b-6b43ed88c63a"
   },
   "source": [
    "### C. Post-processing the LR  model with ROC, optimizing Disparate Impact<a name=\"subparagraph5.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for the predictions on the transformed datasets\n",
    "dataset_transf_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
    "dataset_transf_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "dataset_transf_test_pred = dataset_orig_test.copy(deepcopy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allowed options for the fairness metric which must be optimized for ROC are “Statistical parity difference”, \n",
    "# “Average odds difference”, and “Equal opportunity difference”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "8f4879f1-e2f3-43e6-b78b-d4ec736fb9a9"
   },
   "outputs": [],
   "source": [
    "# Determine the best threshold for classification on the validation set, with fairness constraint.\n",
    "# For that, we can use aif360's Reject Option Classsification\n",
    "\n",
    "ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                 privileged_groups=privileged_groups, \n",
    "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                 num_class_thresh=100, num_ROC_margin=50,\n",
    "                                 metric_name=\"Statistical parity difference\",\n",
    "                                 metric_ub=0.05, \n",
    "                                 metric_lb=-0.05)\n",
    "ROC_di = ROC.fit(dataset_orig_valid, dataset_orig_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "72e51569-8084-4fbe-8410-9e80172cab2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal classification threshold (with fairness constraint) = 0.495\n",
      "Optimal ROC margin = 0.131\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal classification threshold (with fairness constraint) = %.3f\" % ROC_di.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.3f\" % ROC_di.ROC_margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "739d523a-4ede-4845-8e73-d2050964dbad"
   },
   "source": [
    "### D. Fairness metrics for LR model, after correcting for bias (with optimized Disparate Impact)<a name=\"subparagraph5.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ef94aa0b-01d4-4889-878b-ae3eee50979c"
   },
   "outputs": [],
   "source": [
    "# Metrics for the transformed test set\n",
    "dataset_transf_train_pred = ROC_di.predict(dataset_orig_train_pred) \n",
    "dataset_transf_valid_pred = ROC_di.predict(dataset_orig_valid_pred)\n",
    "dataset_transf_test_pred  = ROC_di.predict(dataset_orig_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ef94aa0b-01d4-4889-878b-ae3eee50979c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Results for Logistic Regression after correcting for bias (optimizing Disparate Impact)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the training dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.776\n",
      "Balanced Accuracy:\t\t 0.729\n",
      "Absolute difference in odds:\t 0.109\n",
      "Difference in odds:\t\t 0.106\n",
      "Disparate impact:\t\t 1.019\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the validation dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.795\n",
      "Balanced Accuracy:\t\t 0.744\n",
      "Absolute difference in odds:\t 0.254\n",
      "Difference in odds:\t\t 0.107\n",
      "Disparate impact:\t\t 1.024\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the testing dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.722\n",
      "Balanced Accuracy:\t\t 0.672\n",
      "Absolute difference in odds:\t 0.109\n",
      "Difference in odds:\t\t -0.021\n",
      "Disparate impact:\t\t 0.804\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Results for Logistic Regression after correcting for bias (optimizing Disparate Impact)\"))\n",
    "\n",
    "lr_aft_class_metrics_di = compute_classification_metrics (dataset_orig_train, dataset_transf_train_pred,\n",
    "                                                     dataset_orig_valid, dataset_transf_valid_pred,\n",
    "                                                     dataset_orig_test,  dataset_transf_test_pred)\n",
    "\n",
    "print_classification_metrics(lr_aft_class_metrics_di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing: Check if the Disparate Impact has not become worse\n",
    "#assert lr_aft_class_metrics_di[14] >= lr_bef_class_metrics[14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Post-processing the LR model with ROC, optimizing Difference in Odds<a name=\"subparagraph5.5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for the predictions on the transformed datasets\n",
    "dataset_transf_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
    "dataset_transf_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "dataset_transf_test_pred = dataset_orig_test.copy(deepcopy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the best threshold for classification on the validation set, with fairness constraint.\n",
    "# For that, we can use aif360's Reject Option Classsification\n",
    "\n",
    "# Allowed options for the ROC fairness metric which must be optimized are “Statistical parity difference”, “Average odds difference”, \n",
    "# and “Equal opportunity difference”.\n",
    "\n",
    "ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                 privileged_groups=privileged_groups, \n",
    "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                 num_class_thresh=100, num_ROC_margin=50,\n",
    "                                 metric_name= \"Average odds difference\", # \"Equal opportunity difference\",\n",
    "                                 metric_ub=0.05, \n",
    "                                 metric_lb=-0.05)\n",
    "ROC_aod = ROC.fit(dataset_orig_valid, dataset_orig_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal classification threshold (with fairness constraint) = 0.554\n",
      "Optimal ROC margin = 0.073\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal classification threshold (with fairness constraint) = %.3f\" % ROC_aod.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.3f\" % ROC_aod.ROC_margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Fairness metrics for LR model, after correcting for bias (with optimized Difference in Odds)<a name=\"subparagraph5.6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for the transformed test set\n",
    "dataset_transf_train_pred = ROC_aod.predict(dataset_orig_train_pred) \n",
    "dataset_transf_valid_pred = ROC_aod.predict(dataset_orig_valid_pred)\n",
    "dataset_transf_test_pred  = ROC_aod.predict(dataset_orig_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Results for Logistic Regression after correcting for bias (optimizing Difference in Odds)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the training dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.774\n",
      "Balanced Accuracy:\t\t 0.732\n",
      "Absolute difference in odds:\t 0.109\n",
      "Difference in odds:\t\t 0.036\n",
      "Disparate impact:\t\t 0.92\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the validation dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.79\n",
      "Balanced Accuracy:\t\t 0.749\n",
      "Absolute difference in odds:\t 0.19\n",
      "Difference in odds:\t\t -0.029\n",
      "Disparate impact:\t\t 0.873\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the testing dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.733\n",
      "Balanced Accuracy:\t\t 0.705\n",
      "Absolute difference in odds:\t 0.137\n",
      "Difference in odds:\t\t -0.137\n",
      "Disparate impact:\t\t 0.615\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Results for Logistic Regression after correcting for bias (optimizing Difference in Odds)\"))\n",
    "\n",
    "lr_aft_class_metrics_aod = compute_classification_metrics (dataset_orig_train, dataset_transf_train_pred,\n",
    "                                                           dataset_orig_valid, dataset_transf_valid_pred,\n",
    "                                                           dataset_orig_test,  dataset_transf_test_pred)\n",
    "\n",
    "print_classification_metrics(lr_aft_class_metrics_aod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing: Check if the Difference in Odds  has not become worse\n",
    "#assert lr_aft_class_metrics_aod[13] <= lr_bef_class_metrics[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that the results for post-processing with ROC, optimizing Disparate Impact oroptimizing Absolute Difference in Odd are very much alike (and they are often the same in other runs). Not sure if that is always the case, but for this dataset, it is. Maybe the limited number of records is causing this.\n",
    "\n",
    "* Rather than using ROC postprocessing, aif36 provides another post-processing module, which is aimed at equalizing the odds.\n",
    "\n",
    "* The name of that function is EqOddsPostprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. Post-processing the LR model with EqOddsPostprocessing<a name=\"subparagraph5.7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for the transformed datasets (\"transformed\" = transformed by post processing to equalize the odds)\n",
    "dataset_transf_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
    "dataset_transf_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "dataset_transf_test_pred = dataset_orig_test.copy(deepcopy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters on validation set to equalize odds and apply to create a new dataset\n",
    "\n",
    "cpp = EqOddsPostprocessing(privileged_groups=privileged_groups,\n",
    "                           unprivileged_groups=unprivileged_groups,\n",
    "                           seed=1994)\n",
    "\n",
    "cpp = cpp.fit(dataset_orig_valid, dataset_orig_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H. Fairness metrics for LR model, after correcting for bias (with optimized Equalized Odds)<a name=\"subparagraph5.8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transf_train_pred = cpp.predict(dataset_orig_train_pred)\n",
    "dataset_transf_valid_pred = cpp.predict(dataset_orig_valid_pred)\n",
    "dataset_transf_test_pred  = cpp.predict(dataset_orig_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Results for Logistic Regression after correcting for bias (optimizing Equalized Odds)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the training dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.646\n",
      "Balanced Accuracy:\t\t 0.632\n",
      "Absolute difference in odds:\t 0.09\n",
      "Difference in odds:\t\t 0.09\n",
      "Disparate impact:\t\t 1.086\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the validation dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.643\n",
      "Balanced Accuracy:\t\t 0.625\n",
      "Absolute difference in odds:\t 0.018\n",
      "Difference in odds:\t\t -0.01\n",
      "Disparate impact:\t\t 1.01\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the testing dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.711\n",
      "Balanced Accuracy:\t\t 0.726\n",
      "Absolute difference in odds:\t 0.021\n",
      "Difference in odds:\t\t -0.007\n",
      "Disparate impact:\t\t 0.724\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Results for Logistic Regression after correcting for bias (optimizing Equalized Odds)\"))\n",
    "\n",
    "lr_aft_class_metrics_eqo = compute_classification_metrics (dataset_orig_train, dataset_transf_train_pred,\n",
    "                                                     dataset_orig_valid, dataset_transf_valid_pred,\n",
    "                                                     dataset_orig_test,  dataset_transf_test_pred)\n",
    "\n",
    "print_classification_metrics(lr_aft_class_metrics_eqo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extreme Gradient Boosting (XGB) <a name=\"paragraph6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Build an XGB model on training data<a name=\"subparagraph6.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, tune the parameters for the XGB algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://medium.com/all-things-ai/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae\n",
    "* https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for the predictions on the original datasets\n",
    "dataset_orig_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
    "dataset_orig_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "dataset_orig_test_pred  = dataset_orig_test.copy(deepcopy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning the parameters of XGB Classifier, using Grid Seacrh\n",
    "\n",
    "#### The following parameters will be tuned:\n",
    "* colsample_bytree:  percentage of features (columns) will be used for building each tree\n",
    "* min_child_weight: minimum number of records that is required in a tree node to try to split on another feature; if the number of records falls below this minimu, the node will not be split\n",
    "* learning_rate: the factor with which new trees are weighted to correct the wrong predictions of the previous tree\n",
    "* n_estimators: the number of trees on which the final prediction is based\n",
    "* max_depth: the maximum number of levels that a single tree can have\n",
    "* gamma:  specifies the minimum loss reduction required to make a split\n",
    "\n",
    "Parameter values will be taken close to the values used on the training set.\n",
    "\n",
    "\n",
    "#### Referrences:\n",
    "* https://machinelearningmastery.com/tune-learning-rate-for-gradient-boosting-with-xgboost-in-python/\n",
    "* https://www.mikulskibartosz.name/xgboost-hyperparameter-tuning-in-python-using-grid-search/\n",
    "* https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = XGBClassifier(base_score=0.7, eval_metric=\"error\", seed=1994)\n",
    "\n",
    "parameters = {'colsample_bytree': [0.1, 0.5, 1],\n",
    "              'min_child_weight': [5, 15, 25],\n",
    "              'learning_rate': [0.001, 0.05, 0.1, 0.2, 0.30],\n",
    "              'n_estimators': [10, 50, 100],\n",
    "              'max_depth':[2, 4, 6],\n",
    "              'gamma': [0, 0.001, 0.005]              \n",
    "             }\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=estimator,\n",
    "                           param_grid=parameters,\n",
    "                           scoring = 'balanced_accuracy',\n",
    "                           n_jobs = 1,\n",
    "                           cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune_xgb_params = True\n",
    "tune_xgb_params = False\n",
    "\n",
    "if tune_xgb_params:\n",
    "    start = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    \n",
    "    xgbmod  = grid_search.best_estimator_\n",
    "    minutes= (end - start) /60\n",
    "    print( \"It took %.2f minutes to process\" % minutes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.7, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5,\n",
       "              enable_categorical=False, eval_metric='error', gamma=0, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.3, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=15, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=50, n_jobs=6, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=1994, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=1994, subsample=1, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy and paste output from previous cell here (but remove missing parameter because that gives an error)\n",
    "xgbmod = XGBClassifier(base_score=0.7, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.5,\n",
    "              enable_categorical=False, eval_metric='error', gamma=0, gpu_id=-1,\n",
    "              importance_type=None, interaction_constraints='',\n",
    "              learning_rate=0.3, max_delta_step=0, max_depth=2,\n",
    "              min_child_weight=15, monotone_constraints='()',\n",
    "              n_estimators=50, n_jobs=6, num_parallel_tree=1, predictor='auto',\n",
    "              random_state=1994, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "              seed=1994, subsample=1, tree_method='exact',\n",
    "              validate_parameters=1, verbosity=None)\n",
    "\n",
    "# tune_xgb_params can be set to false, so no grid search will be performed in a next run\n",
    "\n",
    "# Alternatively, perform grid search and use:\n",
    "# xgbmod  = grid_search.best_estimator_\n",
    "\n",
    "xgbmod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Fairness metrics for XGB model, before correcting for bias<a name=\"subparagraph6.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction probs for training, validation and testing data\n",
    "y_train_pred_prob = xgbmod.predict_proba(X_train)[:,fav_idx]\n",
    "y_valid_pred_prob = xgbmod.predict_proba(X_valid)[:,fav_idx]\n",
    "y_test_pred_prob  = xgbmod.predict_proba(X_test)[:,fav_idx]\n",
    "\n",
    "class_thresh = 0.5\n",
    "\n",
    "dataset_orig_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
    "dataset_orig_valid_pred.scores = y_valid_pred_prob.reshape(-1,1)\n",
    "dataset_orig_test_pred.scores  = y_test_pred_prob.reshape(-1,1)\n",
    "\n",
    "y_train_pred = np.zeros_like(dataset_orig_train_pred.labels)\n",
    "y_train_pred[y_train_pred_prob >= class_thresh] = dataset_orig_train_pred.favorable_label\n",
    "y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_orig_train_pred.unfavorable_label\n",
    "dataset_orig_train_pred.labels = y_train_pred\n",
    "\n",
    "y_valid_pred = np.zeros_like(dataset_orig_valid_pred.labels)\n",
    "y_valid_pred[y_valid_pred_prob >= class_thresh] = dataset_orig_valid_pred.favorable_label\n",
    "y_valid_pred[~(y_valid_pred_prob >= class_thresh)] = dataset_orig_valid_pred.unfavorable_label\n",
    "dataset_orig_valid_pred.labels = y_valid_pred\n",
    "\n",
    "y_test_pred = np.zeros_like(dataset_orig_test_pred.labels)\n",
    "y_test_pred[y_test_pred_prob >= class_thresh] = dataset_orig_test_pred.favorable_label\n",
    "y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_orig_test_pred.unfavorable_label\n",
    "dataset_orig_test_pred.labels = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Results for Extreme Gradient Boosting before correcting for bias by post-processing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the training dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.799\n",
      "Balanced Accuracy:\t\t 0.722\n",
      "Absolute difference in odds:\t 0.106\n",
      "Difference in odds:\t\t -0.106\n",
      "Disparate impact:\t\t 0.783\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the validation dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.738\n",
      "Balanced Accuracy:\t\t 0.653\n",
      "Absolute difference in odds:\t 0.136\n",
      "Difference in odds:\t\t -0.108\n",
      "Disparate impact:\t\t 0.81\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the testing dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.767\n",
      "Balanced Accuracy:\t\t 0.703\n",
      "Absolute difference in odds:\t 0.147\n",
      "Difference in odds:\t\t -0.147\n",
      "Disparate impact:\t\t 0.644\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"### Results for Extreme Gradient Boosting before correcting for bias by post-processing\"))\n",
    "\n",
    "xgb_bef_class_metrics= compute_classification_metrics (dataset_orig_train, dataset_orig_train_pred,\n",
    "                                                       dataset_orig_valid, dataset_orig_valid_pred,\n",
    "                                                       dataset_orig_test,  dataset_orig_test_pred)\n",
    "\n",
    "print_classification_metrics(xgb_bef_class_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Post-processing the XGB  model with ROC, optimizing Disparate Impact <a name=\"subparagraph6.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for the predictions on the transformed datasets\n",
    "dataset_transf_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
    "dataset_transf_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "dataset_transf_test_pred = dataset_orig_test.copy(deepcopy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness metric already specified previously: Statistical Parity Difference is used.\n",
    "\n",
    "ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                 privileged_groups=privileged_groups, \n",
    "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                 num_class_thresh=100, num_ROC_margin=50,\n",
    "                                 metric_name=\"Statistical parity difference\",\n",
    "                                 metric_ub=0.05, \n",
    "                                 metric_lb=-0.05)\n",
    "\n",
    "ROC_di = ROC.fit(dataset_orig_valid, dataset_orig_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal classification threshold (with fairness constraint) = 0.5445\n",
      "Optimal ROC margin = 0.0929\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal classification threshold (with fairness constraint) = %.4f\" % ROC_di.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.4f\" % ROC_di.ROC_margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Fairness metrics for XGB model, after correcting for bias (with optimized Disparate Impact)<a name=\"subparagraph6.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-process predictions\n",
    "dataset_transf_train_pred = ROC_di.predict(dataset_orig_train_pred) \n",
    "dataset_transf_valid_pred = ROC_di.predict(dataset_orig_valid_pred)\n",
    "dataset_transf_test_pred  = ROC_di.predict(dataset_orig_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Results for Extreme Gradient Boosting after correcting for bias by post-processing - Disparate Impact"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the training dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.78\n",
      "Balanced Accuracy:\t\t 0.748\n",
      "Absolute difference in odds:\t 0.108\n",
      "Difference in odds:\t\t 0.108\n",
      "Disparate impact:\t\t 1.02\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the validation dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.767\n",
      "Balanced Accuracy:\t\t 0.727\n",
      "Absolute difference in odds:\t 0.175\n",
      "Difference in odds:\t\t 0.086\n",
      "Disparate impact:\t\t 1.042\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the testing dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.722\n",
      "Balanced Accuracy:\t\t 0.672\n",
      "Absolute difference in odds:\t 0.071\n",
      "Difference in odds:\t\t 0.071\n",
      "Disparate impact:\t\t 0.922\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"### Results for Extreme Gradient Boosting after correcting for bias by post-processing - Disparate Impact\"))\n",
    "\n",
    "xgb_aft_class_metrics_di= compute_classification_metrics (dataset_orig_train, dataset_transf_train_pred,\n",
    "                                                       dataset_orig_valid, dataset_transf_valid_pred,\n",
    "                                                       dataset_orig_test,  dataset_transf_test_pred)\n",
    "\n",
    "print_classification_metrics(xgb_aft_class_metrics_di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing: Check if the Disparate Impact has not become worse\n",
    "#assert xgb_aft_class_metrics_di[14] >= xgb_bef_class_metrics[14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Post-processing the XGB  model with ROC, optimizing Difference in Odds<a name=\"subparagraph6.5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for the predictions on the transformed datasets\n",
    "dataset_transf_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
    "dataset_transf_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "dataset_transf_test_pred = dataset_orig_test.copy(deepcopy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_aod = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                 privileged_groups=privileged_groups, \n",
    "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                 num_class_thresh=100, num_ROC_margin=50,\n",
    "                                 metric_name=\"Average odds difference\",\n",
    "                                 metric_ub=0.05, \n",
    "                                 metric_lb=-0.05)\n",
    "\n",
    "ROC_aod = ROC.fit(dataset_orig_valid, dataset_orig_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal classification threshold (with fairness constraint) = 0.5445\n",
      "Optimal ROC margin = 0.0929\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal classification threshold (with fairness constraint) = %.4f\" % ROC_aod.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.4f\" % ROC_aod.ROC_margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Fairness metrics for XGB model, after correcting for bias (with optimized Difference in Odds)<a name=\"subparagraph6.6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-process predictions\n",
    "dataset_transf_train_pred = ROC_aod.predict(dataset_orig_train_pred) \n",
    "dataset_transf_valid_pred = ROC_aod.predict(dataset_orig_valid_pred)\n",
    "dataset_transf_test_pred  = ROC_aod.predict(dataset_orig_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Results for Extreme Gradient Boosting after correcting for bias by post-processing - Difference in Odds"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the training dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.78\n",
      "Balanced Accuracy:\t\t 0.748\n",
      "Absolute difference in odds:\t 0.108\n",
      "Difference in odds:\t\t 0.108\n",
      "Disparate impact:\t\t 1.02\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the validation dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.767\n",
      "Balanced Accuracy:\t\t 0.727\n",
      "Absolute difference in odds:\t 0.175\n",
      "Difference in odds:\t\t 0.086\n",
      "Disparate impact:\t\t 1.042\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the testing dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.722\n",
      "Balanced Accuracy:\t\t 0.672\n",
      "Absolute difference in odds:\t 0.071\n",
      "Difference in odds:\t\t 0.071\n",
      "Disparate impact:\t\t 0.922\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"### Results for Extreme Gradient Boosting after correcting for bias by post-processing - Difference in Odds\"))\n",
    "\n",
    "xgb_aft_class_metrics_aod= compute_classification_metrics (dataset_orig_train, dataset_transf_train_pred,\n",
    "                                                           dataset_orig_valid, dataset_transf_valid_pred,\n",
    "                                                           dataset_orig_test,  dataset_transf_test_pred)\n",
    "\n",
    "print_classification_metrics(xgb_aft_class_metrics_aod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing: Check if the Difference in Odds Impact has not become worse\n",
    "# assert xgb_aft_class_metrics_aod[13] <= xgb_bef_class_metrics[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. Post-processing the XGB  model, optimizing Equalized Odds<a name=\"subparagraph6.7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for the transformed datasets (\"transformed\" = transformed by post processing to equalize the odds)\n",
    "dataset_transf_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
    "dataset_transf_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "dataset_transf_test_pred = dataset_orig_test.copy(deepcopy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters on validation set to equalize odds and apply to create a new dataset\n",
    "\n",
    "cpp = EqOddsPostprocessing(privileged_groups=privileged_groups,\n",
    "                           unprivileged_groups=unprivileged_groups,\n",
    "                           seed=1994)\n",
    "\n",
    "cpp = cpp.fit(dataset_orig_valid, dataset_orig_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H. Fairness metrics for XGB model, after correcting for bias (with optimized Equalized Odds)<a name=\"subparagraph6.8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transf_train_pred = cpp.predict(dataset_orig_train_pred)\n",
    "dataset_transf_valid_pred = cpp.predict(dataset_orig_valid_pred)\n",
    "dataset_transf_test_pred  = cpp.predict(dataset_orig_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Results for Extreme Gradient Boosting after correcting for bias by post-processing - Difference in Odds"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the training dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.611\n",
      "Balanced Accuracy:\t\t 0.561\n",
      "Absolute difference in odds:\t 0.175\n",
      "Difference in odds:\t\t -0.038\n",
      "Disparate impact:\t\t 0.964\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the validation dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.576\n",
      "Balanced Accuracy:\t\t 0.523\n",
      "Absolute difference in odds:\t 0.021\n",
      "Difference in odds:\t\t -0.004\n",
      "Disparate impact:\t\t 1.009\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Results for the testing dataset\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t\t 0.7\n",
      "Balanced Accuracy:\t\t 0.682\n",
      "Absolute difference in odds:\t 0.142\n",
      "Difference in odds:\t\t -0.02\n",
      "Disparate impact:\t\t 0.776\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"### Results for Extreme Gradient Boosting after correcting for bias by post-processing - Difference in Odds\"))\n",
    "\n",
    "xgb_aft_class_metrics_eqo= compute_classification_metrics (dataset_orig_train, dataset_transf_train_pred,\n",
    "                                                           dataset_orig_valid, dataset_transf_valid_pred,\n",
    "                                                           dataset_orig_test,  dataset_transf_test_pred)\n",
    "\n",
    "print_classification_metrics(xgb_aft_class_metrics_eqo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have lists storing metrics for:\n",
    "* Logistic regresssion, no corrections:                                          lr_bef_class_metrics\n",
    "* Logistic regresssion, ROC post-processing, optimizing Disparate Impact:        lr_aft_class_metrics_di\n",
    "* Logistic regresssion, ROC post-processing, optimizing Difference in Odds:      lr_aft_class_metrics_aod\n",
    "* Logistic regresssion, ROC post-processing, optimizing Equalized Odds:          lr_aft_class_metrics_eqo\n",
    "* Extreme Gradient Boosting, no corrections:                                     xgb_bef_class_metrics\n",
    "* Extreme Gradient Boosting, ROC post-processing, optimizing Disparate Impact:   xgb_aft_class_metrics_di\n",
    "* Extreme Gradient Boosting, ROC post-processing, optimizing Difference in Odds: xgb_aft_class_metrics_aod\n",
    "* Extreme Gradient Boosting, ROC post-processing, optimizing Equalized Odds:     xgb_aft_class_metrics_eqo\n",
    "\n",
    "All metrics are computed for Training, Validatiopn, and Testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Metric</th>\n",
       "      <th>LR</th>\n",
       "      <th>LR-PP (DI)</th>\n",
       "      <th>LR-PP (AOD)</th>\n",
       "      <th>LR-PP (EQO)</th>\n",
       "      <th>XGB</th>\n",
       "      <th>XGB-PP (DI)</th>\n",
       "      <th>XGB-PP (AOD)</th>\n",
       "      <th>XGB-PP (EQO)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>Acc</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Bal Acc</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Abs Odds Diff</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Odds Diff</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Disp Imp</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Validation</td>\n",
       "      <td>Acc</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>Bal Acc</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>Abs Odds Diff</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>Odds Diff</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>Disp Imp</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Acc</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>Bal Acc</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>Abs Odds Diff</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>Odds Diff</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>Disp Imp</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset         Metric    LR  LR-PP (DI)  LR-PP (AOD)  LR-PP (EQO)  \\\n",
       "0     Training            Acc  0.78        0.78         0.77         0.65   \n",
       "1                     Bal Acc  0.70        0.73         0.73         0.63   \n",
       "2               Abs Odds Diff  0.10        0.11         0.11         0.09   \n",
       "3                   Odds Diff -0.10        0.11         0.04         0.09   \n",
       "4                    Disp Imp  0.79        1.02         0.92         1.09   \n",
       "5   Validation            Acc  0.76        0.80         0.79         0.64   \n",
       "6                     Bal Acc  0.68        0.74         0.75         0.62   \n",
       "7               Abs Odds Diff  0.21        0.25         0.19         0.02   \n",
       "8                   Odds Diff -0.21        0.11        -0.03        -0.01   \n",
       "9                    Disp Imp  0.73        1.02         0.87         1.01   \n",
       "10     Testing            Acc  0.79        0.72         0.73         0.71   \n",
       "11                    Bal Acc  0.72        0.67         0.70         0.73   \n",
       "12              Abs Odds Diff  0.26        0.11         0.14         0.02   \n",
       "13                  Odds Diff -0.26       -0.02        -0.14        -0.01   \n",
       "14                   Disp Imp  0.53        0.80         0.61         0.72   \n",
       "\n",
       "     XGB  XGB-PP (DI)  XGB-PP (AOD)  XGB-PP (EQO)  \n",
       "0   0.80         0.78          0.78          0.61  \n",
       "1   0.72         0.75          0.75          0.56  \n",
       "2   0.11         0.11          0.11          0.17  \n",
       "3  -0.11         0.11          0.11         -0.04  \n",
       "4   0.78         1.02          1.02          0.96  \n",
       "5   0.74         0.77          0.77          0.58  \n",
       "6   0.65         0.73          0.73          0.52  \n",
       "7   0.14         0.17          0.17          0.02  \n",
       "8  -0.11         0.09          0.09         -0.00  \n",
       "9   0.81         1.04          1.04          1.01  \n",
       "10  0.77         0.72          0.72          0.70  \n",
       "11  0.70         0.67          0.67          0.68  \n",
       "12  0.15         0.07          0.07          0.14  \n",
       "13 -0.15         0.07          0.07         -0.02  \n",
       "14  0.64         0.92          0.92          0.78  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = [lr_bef_class_metrics,  lr_aft_class_metrics_di,  lr_aft_class_metrics_aod, lr_aft_class_metrics_eqo,\n",
    "           xgb_bef_class_metrics, xgb_aft_class_metrics_di, xgb_aft_class_metrics_aod, xgb_aft_class_metrics_eqo\n",
    "           ]\n",
    "rounded_list = [np.round(num, 2) for num in all_data]\n",
    "\n",
    "df_table = pd.DataFrame (rounded_list).transpose()\n",
    "new_col_names=[\"LR\", \"LR-PP (DI)\",  \"LR-PP (AOD)\", \"LR-PP (EQO)\", \"XGB\", \"XGB-PP (DI)\",  \"XGB-PP (AOD)\", \"XGB-PP (EQO)\" ]\n",
    "\n",
    "df_table = df_table.set_axis(new_col_names, axis=1)\n",
    "dataset = pd.DataFrame([\"Training\",\" \",\" \", \" \", \" \",\n",
    "                       \"Validation\",\" \",\" \", \" \", \" \",\n",
    "                       \"Testing\",\" \",\" \", \" \", \" \"])\n",
    "df_table.insert (0, \"Dataset\", dataset)\n",
    "\n",
    "metric = [\"Acc\", \"Bal Acc\", \"Abs Odds Diff\", \"Odds Diff\", \"Disp Imp\"] * 3\n",
    "              \n",
    "df_table.insert (1, \"Metric\", metric)\n",
    "#df_table=df_table.reset_index(drop=True)\n",
    "df_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
